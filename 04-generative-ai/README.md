# Generative AI & LLM Systems

This module focuses on **production-grade LLM applications**, not prompt demos.
It reflects real enterprise GenAI patterns.

## Objectives
- Build reliable LLM-powered systems
- Reduce hallucinations
- Integrate private data safely
- Control cost, latency, and behavior

## Covered Topics
- Prompt engineering
- Embeddings
- Retrieval Augmented Generation (RAG)
- Vector databases
- LLM orchestration

## Tools & Technologies
- OpenAI / Azure OpenAI APIs
- LangChain / LlamaIndex
- FAISS / Chroma / Pinecone

## Key Architectural Patterns
- RAG over fine-tuning
- Stateless LLM services
- Context grounding via vector search

## Outcome
Enterprise-ready GenAI services that can be embedded into real products.
